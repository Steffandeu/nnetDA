{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.51919818e-02   3.75000000e+00]\n",
      " [  2.91430984e-02   3.76000000e+00]\n",
      " [  7.04747067e-02   3.77000000e+00]\n",
      " ..., \n",
      " [  1.07798118e-01   4.99700000e+01]\n",
      " [  1.00682466e-01   4.99800000e+01]\n",
      " [  1.44877283e-01   4.99900000e+01]]\n",
      "------------------------------\n",
      "Step 1 of 436\n",
      "beta = 0, RF = 1.16666667e-08\n",
      "\n",
      "Taping action evaluation...\n",
      "Done!\n",
      "Time = 12.4449679852 s\n",
      "\n",
      "Beginning optimization...\n",
      "Optimization complete!\n",
      "Time = 0.638620853424 s\n",
      "Exit flag = 0\n",
      "Exit message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "Iterations = 1\n",
      "Obj. function value = [  4.96052176e-10]\n",
      "\n",
      "------------------------------\n",
      "Step 2 of 436\n",
      "beta = 1, RF = 1.28333333e-08\n",
      "\n",
      "Taping action evaluation...\n",
      "Done!\n",
      "Time = 12.3659801483 s\n",
      "\n",
      "Beginning optimization...\n",
      "Optimization complete!\n",
      "Time = 0.668935060501 s\n",
      "Exit flag = 0\n",
      "Exit message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "Iterations = 1\n",
      "Obj. function value = [  5.45244673e-10]\n",
      "\n",
      "------------------------------\n",
      "Step 3 of 436\n",
      "beta = 2, RF = 1.41166667e-08\n",
      "\n",
      "Taping action evaluation...\n",
      "Done!\n",
      "Time = 19.0587871075 s\n",
      "\n",
      "Beginning optimization...\n",
      "Optimization complete!\n",
      "Time = 0.657111883163 s\n",
      "Exit flag = 0\n",
      "Exit message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "Iterations = 1\n",
      "Obj. function value = [  5.99308091e-10]\n",
      "\n",
      "------------------------------\n",
      "Step 4 of 436\n",
      "beta = 3, RF = 1.55283333e-08\n",
      "\n",
      "Taping action evaluation...\n",
      "Done!\n",
      "Time = 12.5405628681 s\n",
      "\n",
      "Beginning optimization...\n",
      "Optimization complete!\n",
      "Time = 0.698079109192 s\n",
      "Exit flag = 0\n",
      "Exit message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "Iterations = 1\n",
      "Obj. function value = [  6.58732018e-10]\n",
      "\n",
      "------------------------------\n",
      "Step 5 of 436\n",
      "beta = 4, RF = 1.70811667e-08\n",
      "\n",
      "Taping action evaluation...\n",
      "Done!\n",
      "Time = 12.2641589642 s\n",
      "\n",
      "Beginning optimization...\n",
      "Optimization complete!\n",
      "Time = 0.651124954224 s\n",
      "Exit flag = 0\n",
      "Exit message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "Iterations = 1\n",
      "Obj. function value = [  7.24031091e-10]\n",
      "\n",
      "------------------------------\n",
      "Step 6 of 436\n",
      "beta = 5, RF = 1.87892833e-08\n",
      "\n",
      "Taping action evaluation...\n",
      "Done!\n",
      "Time = 12.1568231583 s\n",
      "\n",
      "Beginning optimization...\n",
      "Optimization complete!\n",
      "Time = 0.657429933548 s\n",
      "Exit flag = 0\n",
      "Exit message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "Iterations = 1\n",
      "Obj. function value = [  7.95802933e-10]\n",
      "\n",
      "------------------------------\n",
      "Step 7 of 436\n",
      "beta = 6, RF = 2.06682117e-08\n",
      "\n",
      "Taping action evaluation...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Example deep neural network annealing.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from varanneal import va_nnet\n",
    "import sys, time\n",
    "\n",
    "ninit = 15#int(sys.argv[1])\n",
    "M = 100#int(sys.argv[2])\n",
    "D_hidden = 250#int(sys.argv[3])\n",
    "adolcID = 0#int(sys.argv[4])\n",
    "\n",
    "# Define the transfer function\n",
    "def sigmoid(x, W, b):\n",
    "    linpart = np.dot(W, x) + b\n",
    "    return 1.0 / (1.0 + np.exp(-linpart))\n",
    "\n",
    "# Network structure\n",
    "N = 3  # Total number of layers\n",
    "D_in = 200  # Number of neurons in the input layer\n",
    "D_out = 100  # Number of neurons in the output layer\n",
    "#D_hidden =   # Number of neurons in the hidden layers\n",
    "\n",
    "structure = np.zeros(N, dtype='int')\n",
    "structure[0] = D_in  # 3 neurons in the input layer\n",
    "structure[N-1] = D_out  # 2 neurons in the output layer\n",
    "for i in range(1, N-1):\n",
    "    structure[i] = D_hidden  # 5 neurons in the hidden layers\n",
    "\n",
    "Lidx = [np.linspace(0, D_in-1, D_in, dtype='int'), np.linspace(0, D_out-1, D_out, dtype='int')]\n",
    "\n",
    "################################################################################\n",
    "# Action/annealing parameters\n",
    "################################################################################\n",
    "# RM, RF0\n",
    "RM = 1.0\n",
    "RF0 = 1.0e-8 * RM * float(np.sum(structure) - structure[0]) / float(structure[0] + structure[-1])\n",
    "# alpha, and beta ladder\n",
    "alpha = 1.1\n",
    "beta_array = np.linspace(0, 435, 436)\n",
    "epochs = 5\n",
    "batch_size = 20\n",
    "################################################################################\n",
    "# Input and output data\n",
    "################################################################################\n",
    "\n",
    "print(np.load('generated_l96_data/l96_001/gen_l96_noisy_0_01.npy'))# has 5 l96 variables\n",
    "\n",
    "data  = np.load('generated_l96_data/l96_001/gen_l96_noisy_0_01.npy')\n",
    "data = data[0:M+D_in+D_out]\n",
    "Didx = 0\n",
    "\n",
    "# normalize\n",
    "#data = data / np.max(np.abs(data))\n",
    "\n",
    "#add noise\n",
    "\n",
    "#noise = np.random.normal(scale=0.02, size=data.shape[0])\n",
    "#data[:, Didx] += noise\n",
    "\n",
    "T = data.shape[1]\n",
    "\n",
    "data_in = np.zeros((M, D_in))\n",
    "data_out = np.zeros((M, D_out))\n",
    "\n",
    "for i in xrange(M):\n",
    "    data_in[i] = data[i:i+D_in, Didx]\n",
    "    data_out[i] = data[i+D_in:i+D_in+D_out, Didx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train_examples = 10000\n",
    "#x_train = x_all[0:train_examples,:]\n",
    "#y_train = y_all[0:train_examples,:]\n",
    "\n",
    "################################################################################\n",
    "# Initial path/parameter guesses\n",
    "################################################################################\n",
    "DHmax = 1000\n",
    "ninitmax = 100\n",
    "np.random.seed(27509436 + (M-1)*D_in*DHmax*ninitmax + D_hidden*ninit)\n",
    "# Neuron states\n",
    "Xin = np.random.randn(D_in)\n",
    "Xin = (Xin - np.average(Xin)) / np.std(Xin)\n",
    "#X0 = [Xin]\n",
    "X0 = np.copy(Xin)\n",
    "for n in xrange(N-2):\n",
    "    X0 = np.append(X0, 0.2*np.random.rand(D_hidden) + 0.4)\n",
    "X0 = np.append(X0, 0.2*np.random.rand(D_out) + 0.4)\n",
    "\n",
    "for m in xrange(M - 1):\n",
    "    Xin = np.random.randn(D_in)\n",
    "    Xin = (Xin - np.average(Xin)) / np.std(Xin)\n",
    "    X0 = np.append(X0, Xin)\n",
    "    for n in xrange(N-2):\n",
    "        X0 = np.append(X0, 0.2*np.random.rand(D_hidden) + 0.4)\n",
    "    X0 = np.append(X0, 0.2*np.random.rand(D_out) + 0.4)\n",
    "\n",
    "X0 = np.array(X0).flatten()\n",
    "\n",
    "# Parameters\n",
    "NP = np.sum(structure[1:]*structure[:-1] + structure[1:])\n",
    "#Pidx = []\n",
    "P0 = np.array([], dtype=np.float64)\n",
    "\n",
    "W_i0 = 0\n",
    "W_if = structure[0]*structure[1]\n",
    "b_i0 = W_if\n",
    "b_if = b_i0 + structure[1]\n",
    "\n",
    "for n in xrange(N - 1):\n",
    "    if n == 0:\n",
    "        Pidx = np.arange(W_i0, W_if, 1, dtype='int')\n",
    "    else:\n",
    "        Pidx = np.append(Pidx, np.arange(W_i0, W_if, 1, dtype='int'))\n",
    "    if n == 0:\n",
    "        P0 = np.append(P0, (2.0*np.random.rand(structure[n]*structure[n+1]) - 1.0) / D_in)\n",
    "    else:\n",
    "        P0 = np.append(P0, (2.0*np.random.rand(structure[n]*structure[n+1]) - 1.0) / D_hidden)\n",
    "    P0 = np.append(P0, np.zeros(structure[n+1]))\n",
    "\n",
    "    if n < N - 2:\n",
    "        W_i0 = b_if\n",
    "        W_if = W_i0 + structure[n+1]*structure[n+2]\n",
    "        b_i0 = W_if\n",
    "        b_if = b_i0 + structure[n+2]\n",
    "\n",
    "P0 = np.array(P0).flatten()\n",
    "Pidx = np.array(Pidx).flatten().tolist()\n",
    "\n",
    "################################################################################\n",
    "# Annealing\n",
    "################################################################################\n",
    "# Initialize Annealer\n",
    "anneal1 = va_nnet.Annealer()\n",
    "# Set the network structure\n",
    "anneal1.set_structure(structure)\n",
    "# Set the activation function\n",
    "anneal1.set_activation(sigmoid)\n",
    "# Set the input and output data\n",
    "anneal1.set_input_data(data_in)\n",
    "anneal1.set_output_data(data_out)\n",
    "\n",
    "# Run the annealing using L-BFGS-B\n",
    "BFGS_options = {'gtol':1.0e-12, 'ftol':1.0e-10, 'maxfun':1000000, 'maxiter':1000000}\n",
    "tstart = time.time()\n",
    "anneal1.anneal(X0, P0, alpha, beta_array, RM, RF0, Pidx, Lidx=Lidx,\n",
    "               method='L-BFGS-B', opt_args=BFGS_options, adolcID=adolcID)\n",
    "print(\"\\nADOL-C annealing completed in %f s.\"%(time.time() - tstart))\n",
    "\n",
    "# Save the results of annealing\n",
    "#anneal1.save_states(\"L%d_%s_%dex/states_%d.npy\"%(L, suffix, M, ninit))\n",
    "#anneal1.save_params(\"params.npy\")\n",
    "#anneal1.save_paths(\"l96_out_data/DH%d_%dex/io_%d.npy\"%(D_hidden, M, ninit))\n",
    "anneal1.save_io(\"l96_out_data/DH%d_%dex/io_%d.npy\"%(D_hidden, M, ninit))\n",
    "anneal1.save_Wb(\"l96_out_data/DH%d_%dex/W_%d.npy\"%(D_hidden, M, ninit),\n",
    "                \"l96_out_data/DH%d_%dex/b_%d.npy\"%(D_hidden, M, ninit))\n",
    "anneal1.save_action_errors(\"l96_out_data/DH%d_%dex/action_errors_%d.npy\"%(D_hidden, M, ninit))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
