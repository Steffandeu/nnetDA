{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate data set\n",
    "def fib(n):\n",
    "    fib = [1,1]\n",
    "    for i in range(n - 2):\n",
    "        fib.append(fib[i] + fib[i + 1])\n",
    "    return fib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Architecture\n",
    "# Trying out a simple 1 layer\n",
    "input_layer = 1\n",
    "hidden_layer = 10\n",
    "output_layer = 1\n",
    "\n",
    "# Initialize weights\n",
    "# weight_in has shape (10, 1)\n",
    "# weight_rec has shape (10, 1)\n",
    "# weight_out has shape (1, 10)\n",
    "weight_in = 2*np.random.random((hidden_layer, input_layer)) - 1\n",
    "weight_rec = 2*np.random.random((hidden_layer, input_layer)) - 1\n",
    "weight_out = 2*np.random.random((output_layer, hidden_layer)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "# Prepare input and output\n",
    "length = 5\n",
    "x = fib(length)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    if derivative:\n",
    "        return x * (1 - x)\n",
    "    else:\n",
    "        return 1 / (1 + np.exp(x))\n",
    "\n",
    "def update_hidden_state(x, y_prev, weight_in, weight_rec):\n",
    "    \"\"\"    \n",
    "    This will compute the state of the hidden layer using the input layer and the output from previous time step\n",
    "    \"\"\"\n",
    "    return x * weights + y_prev * weight_rec\n",
    "\n",
    "def update_output(S_hidden, weight_out):\n",
    "    return sigmoid(np.dot(S_hidden, wieight_out))\n",
    "    \n",
    "def feedfoward(x, weights, weight_rec, weight_out):\n",
    "    \"\"\"    \n",
    "    Takes the full sequence and weights of the network and propagates the ouptut through time.\n",
    "    \"\"\"\n",
    "    T = x.shape[0]\n",
    "    # Vector to store the states of the hidden layer\n",
    "    S_hidden = np.zeros(T)\n",
    "    S_out = np.zeros(T)\n",
    "    \n",
    "    # Compute the hidden state and output from time 0 to time T\n",
    "    for i in range(T):\n",
    "        if i == 0:\n",
    "            y_prev = 0\n",
    "        S_hidden[i] = update_hidden_state(x, y_prev, weight_in, weight_rec)\n",
    "        S_out = update_output(S_hidden[i], weight_out)\n",
    "    \n",
    "    return S_hidden, S_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_grad(x2, y_true):\n",
    "    \"\"\"Computes the gradient of the cost with respect to the output\"\"\"\n",
    "    num_examples = 1\n",
    "    return 2.0 * (y_true - x2) / num_examples\n",
    "\n",
    "def backward_gradient(x, weight_in, weight_rec, weight_out, S_hidden, S_out):\n",
    "    \"\"\"\n",
    "    Computes the backward gradients and returns the total gradient over the full time series\n",
    "    \n",
    "    x: full time series\n",
    "    weight_in: weights mapping input to hidden layer\n",
    "    weight_rec: weights mapping previous output to hidden layer\n",
    "    weight_out: weights mapping hidden layer to output layer\n",
    "    S_hidden: vector containing the states of the hidden layer over the full time series\n",
    "    S_out: vector containing the predicted value of the output over the full time series\n",
    "    \n",
    "    \"\"\"\n",
    "    grad_weight_in = 0\n",
    "    grad_weight_rec = 0\n",
    "    grad_weight_out = 0\n",
    "    grad_over_time = np.zeros(len(x) + 1)\n",
    "    grad_over_time[-1] = output_grad(S_out[-1], x[-1])\n",
    "    \n",
    "    for i in range(len(x), 0, -1):\n",
    "        grad_weight_out += grad_over_time[i] * weight_out\n",
    "        grad_weight_in += grad_over_time[i] * weight_out * x[i-1]\n",
    "        grad_weight_rec += grad_over_time[i] * weight_out * S[i-1]\n",
    "        grad_over_time[i - 1] = grad_over_time[i] * weight_out * weight_rec\n",
    "        \n",
    "    return (grad_weight_in, grad_weight_rec, grad_weight_out) , grad_over_time\n",
    "\n",
    "def update_rprop(S_hidden, S_out, y_true):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "def train(x, weight_in, weight_rec, weight_out, iterations=iterations):\n",
    "    \"\"\"\n",
    "    Used to train the system using the backpropagation through time (BPTT) algorithm. \n",
    "    Planning on adding a varanneal implementation as well in the future.\n",
    "    \"\"\"\n",
    "    # let T = len(x), the length of the sequence\n",
    "    T = len(x)\n",
    "        \n",
    "    # feed forward on network\n",
    "    # S_hidden contains the state of the hidden layer at each time step. It has shape (T,)\n",
    "    # S_out contains the output of the network at each time step. It has shape (T,)\n",
    "    S_hidden, S_out = feedfoward(x, weight_in, weight_rec, weight_out)\n",
    "     \n",
    "    # update weights\n",
    "    \n",
    "    return w0_unf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 =  [ 0.  1.] \n",
      "\n",
      "x1 =  [ 0.91160897  0.59020393 -0.25180838  0.13460722  0.90582773  0.80888926\n",
      "  0.12317568  0.15135944 -0.999715    0.87364744] \n",
      "\n",
      "x2 =  [ 0.11214306] \n",
      " \n",
      "\n",
      "x0 =  [ 0.11214306  1.        ] \n",
      "\n",
      "x1 =  [ 0.83078064  0.61235068 -0.26730008  0.22135309  0.99955716  0.71107071\n",
      "  0.03153588  0.10683438 -1.0588897   0.79222104] \n",
      "\n",
      "x2 =  [-0.05479745] \n",
      " \n",
      "\n",
      "x0 =  [-0.05479745  2.        ] \n",
      "\n",
      "x1 =  [ 1.8627138   1.1695861  -0.49604692  0.22682704  1.76585561  1.66557645\n",
      "  0.29113012  0.32447555 -1.97051496  1.78708299] \n",
      "\n",
      "x2 =  [ 0.30585973] \n",
      " \n",
      "\n",
      "x0 =  [ 0.30585973  3.        ] \n",
      "\n",
      "x1 =  [ 2.5143752   1.83101498 -0.79767731  0.64041291  2.97312146  2.15987683\n",
      "  0.11958805  0.33264037 -3.16053846  2.39885942] \n",
      "\n",
      "x2 =  [-0.11888546] \n",
      " \n",
      "\n",
      "x0 =  [-0.11888546  5.        ] \n",
      "\n",
      "x1 =  [ 4.64373284  2.92754136 -1.2426188   0.58107479  4.42977388  4.14814599\n",
      "  0.71302787  0.80399925 -4.93584255  4.45455924] \n",
      "\n",
      "x2 =  [ 0.73769282] \n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.72076085, -0.72076085, -0.72076085, -0.72076085, -0.72076085],\n",
       "        [ 0.91160897,  0.91160897,  0.91160897,  0.91160897,  0.91160897]],\n",
       "\n",
       "       [[ 0.19748658,  0.19748658,  0.19748658,  0.19748658,  0.19748658],\n",
       "        [ 0.59020393,  0.59020393,  0.59020393,  0.59020393,  0.59020393]],\n",
       "\n",
       "       [[-0.1381423 , -0.1381423 , -0.1381423 , -0.1381423 , -0.1381423 ],\n",
       "        [-0.25180838, -0.25180838, -0.25180838, -0.25180838, -0.25180838]],\n",
       "\n",
       "       [[ 0.77352861,  0.77352861,  0.77352861,  0.77352861,  0.77352861],\n",
       "        [ 0.13460722,  0.13460722,  0.13460722,  0.13460722,  0.13460722]],\n",
       "\n",
       "       [[ 0.83580237,  0.83580237,  0.83580237,  0.83580237,  0.83580237],\n",
       "        [ 0.90582773,  0.90582773,  0.90582773,  0.90582773,  0.90582773]],\n",
       "\n",
       "       [[-0.87226568, -0.87226568, -0.87226568, -0.87226568, -0.87226568],\n",
       "        [ 0.80888926,  0.80888926,  0.80888926,  0.80888926,  0.80888926]],\n",
       "\n",
       "       [[-0.81716867, -0.81716867, -0.81716867, -0.81716867, -0.81716867],\n",
       "        [ 0.12317568,  0.12317568,  0.12317568,  0.12317568,  0.12317568]],\n",
       "\n",
       "       [[-0.39703805, -0.39703805, -0.39703805, -0.39703805, -0.39703805],\n",
       "        [ 0.15135944,  0.15135944,  0.15135944,  0.15135944,  0.15135944]],\n",
       "\n",
       "       [[-0.52767147, -0.52767147, -0.52767147, -0.52767147, -0.52767147],\n",
       "        [-0.999715  , -0.999715  , -0.999715  , -0.999715  , -0.999715  ]],\n",
       "\n",
       "       [[-0.726094  , -0.726094  , -0.726094  , -0.726094  , -0.726094  ],\n",
       "        [ 0.87364744,  0.87364744,  0.87364744,  0.87364744,  0.87364744]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
